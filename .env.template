# GraphGen 离线部署环境变量配置模板
# 复制此文件为 .env 并填入您的实际配置

# ===== 主要模型配置 =====
# SiliconFlow API配置（或其他兼容OpenAI API的服务）
SYNTHESIZER_API_KEY=sk-your-synthesizer-api-key-here
SYNTHESIZER_BASE_URL=https://api.siliconflow.cn/v1
SYNTHESIZER_MODEL=Qwen/Qwen2.5-7B-Instruct

# 训练模型配置（如果使用双模型模式）
TRAINEE_API_KEY=sk-your-trainee-api-key-here
TRAINEE_BASE_URL=https://api.siliconflow.cn/v1
TRAINEE_MODEL=Qwen/Qwen2.5-7B-Instruct

# ===== 速率限制配置 =====
# 每分钟请求数限制
RPM=1000
# 每分钟Token数限制
TPM=50000

# ===== 离线模式配置 =====
# 启用完全离线模式（使用预下载的模型）
GRAPHGEN_OFFLINE_MODE=true

# Hugging Face离线模式
HF_DATASETS_OFFLINE=1
TRANSFORMERS_OFFLINE=1

# ===== 可选配置 =====
# 日志级别 (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# 工作目录（容器内）
WORKDIR=/app

# ===== 内网部署示例配置 =====
# 如果您使用内网部署的模型服务，请修改以下配置：

# 示例1: 本地Ollama服务
# SYNTHESIZER_BASE_URL=http://host.docker.internal:11434/v1
# SYNTHESIZER_MODEL=qwen2.5:7b-instruct
# SYNTHESIZER_API_KEY=ollama

# 示例2: 内网API服务  
# SYNTHESIZER_BASE_URL=http://your-internal-api.company.com/v1
# SYNTHESIZER_MODEL=your-model-name
# SYNTHESIZER_API_KEY=your-internal-api-key

# 示例3: vLLM服务
# SYNTHESIZER_BASE_URL=http://your-vllm-server:8000/v1
# SYNTHESIZER_MODEL=Qwen/Qwen2.5-7B-Instruct
# SYNTHESIZER_API_KEY=dummy

# ===== 高级配置 =====
# 容器时区
TZ=Asia/Shanghai

# GPU支持（如果使用GPU版本）
# NVIDIA_VISIBLE_DEVICES=all
# NVIDIA_DRIVER_CAPABILITIES=compute,utility