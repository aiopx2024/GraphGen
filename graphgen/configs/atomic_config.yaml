# GraphGen 原子性问答对生成配置文件
# 此配置用于生成基于单个实体或关系的简单直接问答对
# 适用于训练模型的基础知识理解能力

# === 输入配置 ===
input_data_type: raw  # 输入数据类型: raw(原始文档) 或 chunked(预分块数据)
input_file: resources/input_examples/技术通讯_交易中心数字证书的前世今生_trunk.txt  # 输入文件路径，支持json、jsonl、txt格式，参考resources/input_examples中的示例

# === 输出配置 ===
output_data_type: atomic     # 输出数据类型: atomic(原子性), aggregated(聚合型), multi_hop(多跳推理), cot(思维链)
output_data_format: ChatML   # 输出格式: Alpaca(指令微调格式), ShareGPT(对话格式), ChatML(聊天标记语言)

# === 分词器配置 ===
tokenizer: cl100k_base  # 用于Token计数的分词器，支持tiktoken分词器名称和本地分词器路径

# === 外部搜索配置 ===
search:
  enabled: false  # 是否启用外部搜索来补充知识图谱信息
  search_types: ["google"]  # 搜索引擎类型，支持: google, bing, uniprot, wikipedia

# === 文本分块配置 ===
# 控制输入文档的分块方式和参数
chunking:
  chunk_size: 1024          # 最大chunk token数
  overlap_size: 100         # 重叠token数（原子性问答对使用较小重叠）
  strategy: "semantic"      # 切分策略: simple(简单滑动窗口), semantic(语义感知), hierarchical(层次化)
  preserve_boundaries: true # 是否保持语义边界（句子、段落）
  min_chunk_size: 80       # 最小chunk大小，避免产生过小的片段
  language_aware: true      # 是否启用语言感知的token估算
  boundary_markers:         # 语义边界标记
    - "。"    # 中文句号
    - "！"    # 中文感叹号
    - "？"    # 中文问号
    - "."     # 英文句号
    - "!"     # 英文感叹号
    - "?"     # 英文问号
    - "\n\n" # 段落分隔符

# === 知识缺口识别策略 ===
# 通过Quiz测试和判断来识别LLM对知识点的掌握程度
quiz_and_judge_strategy:
  enabled: true        # 是否启用Quiz和判断策略
  quiz_samples: 2      # 生成的Quiz样本数量
  re_judge: false      # 是否重新判断已有的Quiz样本

# === 图遍历策略 ===
# 使用理解损失对子图进行聚类的策略配置
traverse_strategy:
  bidirectional: true           # 是否双向遍历图（正向和反向）
  edge_sampling: max_loss       # 边采样策略: random(随机), max_loss(最大损失优先), min_loss(最小损失优先)
  expand_method: max_width      # 扩展方法: max_width(宽度优先), max_depth(深度优先)
  isolated_node_strategy: ignore  # 孤立节点处理策略: ignore(忽略), add(添加)
  max_depth: 3                  # 图遍历的最大深度（原子性问答对允许更深的遍历）
  max_extra_edges: 5           # 每个方向的最大边数（当expand_method="max_width"时）
  max_tokens: 256              # 限制输入长度（当expand_method="max_tokens"时）
  loss_strategy: only_edge     # 损失计算重点: only_edge(仅边), both(边和节点)
